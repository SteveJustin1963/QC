 
Hello and welcome to Introduction to Quantum Computing for Everyone.

Quantum information science is an exciting field that draws from information theory, computer science, and quantum mechanics to process information in fundamentally new ways.
Quantum mechanics emerged in the 1920s to describe certain puzzling behaviors of elementary constituents of matter and light.

It revolutionized physics and chemistry and led to the inventions like transistors, lasers, and GPS.
Subsequently, we came to understand that information itself can be acquired, encoded, and manipulated in quantum systems, giving birth to the new field of quantum information science.
Quantum information scientists draw on the work of physicists, computer scientists, and mathematicians as well as materials scientists, chemists, and engineers.

Cross-disciplinary teams are applying QIS to new quantum technologies in communications, networking, data security, navigation, and medical diagnostics.
They are also making headway in developing quantum computing systems that may allow us to tackle challenges previously out of reach in areas such as cryptography, logistics, optimization, and across the natural sciences.

As with many emerging technologies, QIS will likely affect how we live and work and may lead to new developments in broader aspects of society such as commerce, governance, privacy, employment, and education.

This evolution contrasts that with that of classical computing, which was a particular solution for a particular problem: How can we make an automated calculator?

As a result, classical computers were designed to mimic the operations that you and I do every day.
We can learn how to program a computer by assuming that it holds information, performs mathematical operations, and can make decisions based on the information it has.

All programs are created with those same building blocks and they largely match the way you and I perform operations ourselves.

The advances made since the 60s have been in four areas:
making faster hardware,
optimizing hardware based on frequent software operations,
redesigning software based on the strengths and weaknesses of the technology,
and making larger and faster storage.

And throughout these advances, the programming approaches have also been improved.
But everything still largely mimics human tasks.
The differences between classical and quantum computing start from those very fundamental building blocks.
Instead of building something that mimics a calculator, scientists discovered something interesting: powerful quantum phenomena.

And then they discovered they could perform computation with it.
So then they asked: how can we use these to perform computation better, faster or bigger than this automatic calculator we made?
Quantum computing is fundamentally different in the ways that it stores information and operates on that information.

In this course, we're going to cover the fundamentals of quantum computing.
We'll answer such questions as: How are quantum computing and classical computing different?

What is a quantum operation? What kinds of problems will quantum computers solve that classical computers cannot?

How does quantum computing leverage phenomena from quantum mechanics? How does this give quantum computers an advantage?

Are bits and qubits the same thing? And if not, how are they different?

So this course will first introduce you to quantum applications and what the hardware looks like.
Then we'll gradually build your knowledge of quantum computing in general.

We'll start with an intuitive introduction to a quantum mechanics phenomenon and the quantum operations that exploit that phenomenon.

Next we'll introduce you to the quantum notation that we use to communicate those concepts.
Finally, we'll go through the mathematical calculations related to that concept.

Don't worry, only basic algebra is required for this course. We'll teach you the rest!

And the idea is that on each subject we progress from ideas related to everyday understandings and gradually build up to the more technical content. If you're not taking this for credit then you can sort of restart every time we have a new concept.

And this course segment will end with an algorithm that illustrates the power of quantum computing.
This course is the first of a two-course sequence. In the next course we will build skills from operations to circuits to algorithms, explore quantum computing concepts via quantum programming.

We'll learn quiskit, IBM software for their current quantum computer, and build up the mathematical skills necessary for understanding more complex algorithms.
